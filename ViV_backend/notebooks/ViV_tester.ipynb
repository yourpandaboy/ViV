{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yourpandaboy/ViV/blob/main/ViV_tester.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP1V5nBZxAmZ",
        "outputId": "c9ae3e55-ac1d-466d-c2b3-926d350355be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6wzwuOm5xYkf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1IHWe59hxl2g"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/okcupid/okcupid_profiles.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N1dEE_dyxu9x"
      },
      "outputs": [],
      "source": [
        "bios = df[[\"essay0\"]].dropna() #get essay0 and dropna\n",
        "test = bios.loc[50000:] #bios for unseen bios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXvtU0Msx2wm",
        "outputId": "966163de-e285-4d8b-932d-00553257c770"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk; nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZxeiHk1-yDon"
      },
      "outputs": [],
      "source": [
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0LDpLIuGyQkS"
      },
      "outputs": [],
      "source": [
        "#simple cleaning\n",
        "def sent_to_words(sentences):\n",
        "    empty_list = []\n",
        "    for sentence in sentences:\n",
        "        empty_list.append(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "#data_words = list(sent_to_words(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wwYIfepFyRVC"
      },
      "outputs": [],
      "source": [
        "#lemmatization\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dosjpuW4zklR"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T8uUKpEVzLqh"
      },
      "outputs": [],
      "source": [
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q7_lQWabw1lP"
      },
      "outputs": [],
      "source": [
        "# load pickle\n",
        "import pickle\n",
        "model = pickle.load(open(\"drive/My Drive/optimal_model_45score.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3EUN1ysj6Bdp"
      },
      "outputs": [],
      "source": [
        "model_predictor = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(model, gamma_threshold=0.001, iterations=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR6zhD_xjS69",
        "outputId": "5ea09a3a-87b7-4efe-9de1-07c40b72681e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[\"lets see here i have a lot of things going on in my life so i guess there is just too much to really say.  i'm just a fun loving person who works and works and studies and works a lot so yea i do need a little bit of time to have fun with new people once and a while and all lol\"]],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# testing unseen data and see which topic it belongs\n",
        "test[:1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nhdM-D2q79xj"
      },
      "outputs": [],
      "source": [
        "text=pd.DataFrame({'text':[\"lets see here i have a lot of things going on in my life so i guess there is just too much to really say.  i'm just a fun loving person who works and works and studies and works a lot so yea i do need a little bit of time to have fun with new people once and a while and all lol\"]})\n",
        "\n",
        "\n",
        "data_words = list(sent_to_words(text['text']))\n",
        "data_nostop= remove_stopwords(data_words)\n",
        "data_lemma = lemmatization(data_nostop, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "id2word = corpora.Dictionary(data_lemma)\n",
        "corpus = [id2word.doc2bow(text) for text in data_lemma]\n",
        "\n",
        "\n",
        "#  predicting new text which is in text dataframe  \n",
        "new_text_corpus =  id2word.doc2bow(text['text'][0].split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k_3el92663_",
        "outputId": "1042b1b0-d3c8-4de1-e86d-5ff06b2a98e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, 0.05586481872554492),\n",
              " (1, 0.08359820348473622),\n",
              " (2, 0.05485567001225815),\n",
              " (3, 0.06724632874431852),\n",
              " (4, 0.053441727204084924),\n",
              " (5, 0.07128743842931094),\n",
              " (6, 0.052276209392113436),\n",
              " (7, 0.06168860165900378),\n",
              " (8, 0.04893378514302692),\n",
              " (9, 0.05820906617825845),\n",
              " (10, 0.05526598526139909),\n",
              " (11, 0.07320271114371739),\n",
              " (12, 0.05389315233918146),\n",
              " (13, 0.10490295426095443),\n",
              " (14, 0.04807692307692308),\n",
              " (15, 0.05725642494516829)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_predictor[new_text_corpus] #highest score at topic 14 and 2, please refer to the word cloud to see the topics better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLsO643-9WL8",
        "outputId": "81f88fd7-dfeb-4444-f61f-3d9c7b51060a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['from my facebook profile:  well about me ...i like to take pictures, go to the movies (sci-fi / comedy / adventure) , hang out with my friends, go dancing, listen to music, or just grab a good book and relax ... i have some pics on flickr, username is nutation  i am nerdy, interesting, and stable']],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test another unseen data\n",
        "test[3:4].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "y3EvPH0T6-V7"
      },
      "outputs": [],
      "source": [
        "text=pd.DataFrame({'text':['from my facebook profile:  well about me ...i like to take pictures, go to the movies (sci-fi / comedy / adventure) , hang out with my friends, go dancing, listen to music, or just grab a good book and relax ... i have some pics on flickr, username is nutation  i am nerdy, interesting, and stable']})\n",
        "\n",
        "\n",
        "data_words = list(sent_to_words(text['text']))\n",
        "lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "id2word = corpora.Dictionary(data_words)\n",
        "corpus = [id2word.doc2bow(text) for text in data_words]\n",
        "\n",
        "\n",
        "#  predicting new text which is in text dataframe  \n",
        "new_text_corpus =  id2word.doc2bow(text['text'][0].split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vht8ucje9mug",
        "outputId": "a2e4c842-0aa2-47a8-9b71-00380b40fc6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, 0.055760991589720824),\n",
              " (1, 0.06540447743853307),\n",
              " (2, 0.046519911518110614),\n",
              " (3, 0.11941354644819976),\n",
              " (4, 0.038842228816230756),\n",
              " (5, 0.08682491154567427),\n",
              " (6, 0.04278552305588437),\n",
              " (7, 0.057287609977288566),\n",
              " (8, 0.04596000241778545),\n",
              " (9, 0.06351741566409252),\n",
              " (10, 0.037654795391328245),\n",
              " (11, 0.06993557260321176),\n",
              " (12, 0.05987039625663064),\n",
              " (13, 0.10710953189391917),\n",
              " (14, 0.04429835183602291),\n",
              " (15, 0.05881473354736708)]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_predictor[new_text_corpus] #topics 14 and 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NtwVgJKhcNb-"
      },
      "outputs": [],
      "source": [
        "#Questions for Alec:\n",
        "#1. Am i doing it the preprocessing of the unseen data correctly? \n",
        "#2. Do you think that \"model_predictor[new_text_corpus]\" could work on a pipeline? THANK YOU SO MUCH!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75Qys9MCcNvg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPv0QHPxOR91dVJHHKcUTAb",
      "include_colab_link": true,
      "name": "ViV_tester.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0c5922e22832e3ab6ce5daa0eb8af1e6f3a64b128ee35ad4eea66691e00b56dc"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
